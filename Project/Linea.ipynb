{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speed running entire project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mmh3\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import networkx as nx\n",
    "import math as math\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies data has 2 columns with 786 rows each.\n",
      "Reviews data has 7 columns with 7855 rows each.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie ID</th>\n",
       "      <th>Reviewer Name</th>\n",
       "      <th>Reviewer URL</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review</th>\n",
       "      <th>Helpful</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0111161</td>\n",
       "      <td>hitchcockthelegend</td>\n",
       "      <td>ur16161013</td>\n",
       "      <td>Some birds aren't meant to be caged.</td>\n",
       "      <td>The Shawshank Redemption is written and direct...</td>\n",
       "      <td>1111</td>\n",
       "      <td>1203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0111161</td>\n",
       "      <td>Sleepin_Dragon</td>\n",
       "      <td>ur15311310</td>\n",
       "      <td>An incredible movie. One that lives with you.</td>\n",
       "      <td>It is no wonder that the film has such a high ...</td>\n",
       "      <td>362</td>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Movie ID       Reviewer Name Reviewer URL  \\\n",
       "0  tt0111161  hitchcockthelegend   ur16161013   \n",
       "1  tt0111161      Sleepin_Dragon   ur15311310   \n",
       "\n",
       "                                           Title  \\\n",
       "0           Some birds aren't meant to be caged.   \n",
       "1  An incredible movie. One that lives with you.   \n",
       "\n",
       "                                              Review  Helpful  Total  \n",
       "0  The Shawshank Redemption is written and direct...     1111   1203  \n",
       "1  It is no wonder that the film has such a high ...      362    394  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get reviews\n",
    "Movies = pd.read_csv('data/movies_786.csv')\n",
    "Reviews = pd.read_csv('data/reviews_786.csv')\n",
    "print(f\"Movies data has {Movies.columns.size} columns with {Movies.shape[0]} rows each.\")\n",
    "print(f\"Reviews data has {Reviews.columns.size} columns with {Reviews.shape[0]} rows each.\")\n",
    "Reviews.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tt0111161',\n",
       " 'tt0068646',\n",
       " 'tt0110912',\n",
       " 'tt0071562',\n",
       " 'tt1375666',\n",
       " 'tt0167260',\n",
       " 'tt0076759',\n",
       " 'tt0120737',\n",
       " 'tt0133093',\n",
       " 'tt0114369',\n",
       " 'tt0211915',\n",
       " 'tt0103064',\n",
       " 'tt1520211',\n",
       " 'tt1156398',\n",
       " 'tt0365748',\n",
       " 'tt0480249',\n",
       " 'tt0455407',\n",
       " 'tt0462322',\n",
       " 'tt0289043',\n",
       " 'tt0463854',\n",
       " 'tt0432021',\n",
       " 'tt0363547',\n",
       " 'tt0120804',\n",
       " 'tt1077258']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract first 10 ids\n",
    "Movies['ID'].head(24).to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Book based model <a id=\"model1\"></a> <br>\n",
    "\n",
    "## Jaccard Similarity on Movie Data <a id=\"jaccard-sim\"></a> <br>\n",
    "\n",
    "\n",
    "Function jaccard, that takes two titles and outputs the estimated jaccard similarity. \\\n",
    "Function max_jaccard takes a list of titles and compare the titles with each other. It then returns the two titles with the highest jaccard similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0111161</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0068646</td>\n",
       "      <td>The Godfather</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                     Title\n",
       "0  tt0111161  The Shawshank Redemption\n",
       "1  tt0068646             The Godfather"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Movies.head(n=2)\n",
    "# Extract all titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Jaccard Similarity: 1.0\n",
      "Dawn of the Dead\n",
      "Dawn of the Dead\n",
      "shocking :o\n"
     ]
    }
   ],
   "source": [
    "# Finds jaccard similarity between two titles.\n",
    "def jaccard(title1, title2):\n",
    "    words1 = set(str(title1).lower().split())\n",
    "    words2 = set(str(title2).lower().split())\n",
    "    \n",
    "    # Compute the intersection and union of the sets\n",
    "    intersection = len(words1.intersection(words2))\n",
    "    union = len(words1) + len(words2) - intersection\n",
    "    \n",
    "    # Calculate and return the Jaccard similarity\n",
    "    return intersection / union if union > 0 else 0.0\n",
    "\n",
    "# Finds title set with highest jaccard similarity\n",
    "def max_jaccard(title_list):\n",
    "    max_similarity = 0.0\n",
    "    idx1 = 0\n",
    "    idx2 = 0\n",
    "    for i in range(len(title_list)):\n",
    "        for j in range(i + 1, len(title_list)):\n",
    "            similarity = jaccard(title_list[i], title_list[j])\n",
    "            if similarity > max_similarity:\n",
    "                idx1 = i\n",
    "                idx2 = j\n",
    "                max_similarity = similarity\n",
    "    return max_similarity, idx1, idx2\n",
    "\n",
    "\"\"\"\n",
    "Example usage for comparing two titles\n",
    "title1 = books_data_1['title'][0]\n",
    "title2 = books_data_1['title'][1]\n",
    "print(title1,title2)\n",
    "similarity = jaccard(title1, title2)\n",
    "print(f\"Jaccard Similarity: {similarity}\")\n",
    "\"\"\"\n",
    "\n",
    "# Example usage with a list of titles\n",
    "title_list = Movies['Title'].tolist()\n",
    "max_similarity, idx1, idx2 = max_jaccard(title_list)\n",
    "print(f\"Max Jaccard Similarity: {max_similarity}\")\n",
    "print(title_list[idx1])\n",
    "print(title_list[idx2])\n",
    "print(\"shocking :o\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding similar titles and reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 943.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score: 0.6\n",
      "Title 1: The Godfather Part II\n",
      "Title 2: The Godfather Part III\n",
      "\n",
      "Similarity Score: 0.6666666666666666\n",
      "Title 1: The Matrix\n",
      "Title 2: The Matrix Reloaded\n",
      "\n",
      "Similarity Score: 0.6666666666666666\n",
      "Title 1: The Matrix\n",
      "Title 2: The Matrix Revolutions\n",
      "\n",
      "Similarity Score: 0.6\n",
      "Title 1: Shaun of the Dead\n",
      "Title 2: Dawn of the Dead\n",
      "\n",
      "Similarity Score: 0.6\n",
      "Title 1: Shaun of the Dead\n",
      "Title 2: Land of the Dead\n",
      "\n",
      "Similarity Score: 0.6\n",
      "Title 1: Shaun of the Dead\n",
      "Title 2: Survival of the Dead\n",
      "\n",
      "Similarity Score: 0.6\n",
      "Title 1: Shaun of the Dead\n",
      "Title 2: Diary of the Dead\n",
      "\n",
      "Similarity Score: 0.6\n",
      "Title 1: Shaun of the Dead\n",
      "Title 2: Day of the Dead\n",
      "\n",
      "Similarity Score: 0.6\n",
      "Title 1: Dawn of the Dead\n",
      "Title 2: Land of the Dead\n",
      "\n",
      "Similarity Score: 1.0\n",
      "Title 1: Dawn of the Dead\n",
      "Title 2: Dawn of the Dead\n",
      "\n",
      "Similarity Score: 0.6\n",
      "Title 1: Dawn of the Dead\n",
      "Title 2: Survival of the Dead\n",
      "\n",
      "Similarity Score: 0.6\n",
      "Title 1: Dawn of the Dead\n",
      "Title 2: Diary of the Dead\n",
      "\n",
      "Similarity Score: 0.6\n",
      "Title 1: Dawn of the Dead\n",
      "Title 2: Day of the Dead\n",
      "\n",
      "Similarity Score: 0.6\n",
      "Title 1: Land of the Dead\n",
      "Title 2: Dawn of the Dead\n",
      "\n",
      "Similarity Score: 0.6\n",
      "Title 1: Land of the Dead\n",
      "Title 2: Survival of the Dead\n",
      "\n",
      "Similarity Score: 0.6\n",
      "Title 1: Land of the Dead\n",
      "Title 2: Diary of the Dead\n",
      "\n",
      "Similarity Score: 0.6\n",
      "Title 1: Land of the Dead\n",
      "Title 2: Day of the Dead\n",
      "\n",
      "Similarity Score: 0.6666666666666666\n",
      "Title 1: Night of the Living Dead\n",
      "Title 2: The Return of the Living Dead\n",
      "\n",
      "Similarity Score: 1.0\n",
      "Title 1: Night of the Living Dead\n",
      "Title 2: Night of the Living Dead\n",
      "\n",
      "Similarity Score: 0.6\n",
      "Title 1: Survival of the Dead\n",
      "Title 2: Diary of the Dead\n",
      "\n",
      "Similarity Score: 0.6\n",
      "Title 1: Survival of the Dead\n",
      "Title 2: Day of the Dead\n",
      "\n",
      "Similarity Score: 0.6\n",
      "Title 1: Diary of the Dead\n",
      "Title 2: Day of the Dead\n",
      "\n",
      "Similarity Score: 0.6666666666666666\n",
      "Title 1: Pet Sematary\n",
      "Title 2: Pet Sematary II\n",
      "\n",
      "Similarity Score: 0.6666666666666666\n",
      "Title 1: The Return of the Living Dead\n",
      "Title 2: Night of the Living Dead\n",
      "\n",
      "Similarity Score: 1.0\n",
      "Title 1: Day of the Dead\n",
      "Title 2: Day of the Dead\n",
      "\n",
      "Similarity Score: 0.6666666666666666\n",
      "Title 1: Die Hard\n",
      "Title 2: Die Hard 4.0\n",
      "\n",
      "Similarity Score: 0.6666666666666666\n",
      "Title 1: Die Hard\n",
      "Title 2: Die Hard 2\n",
      "\n",
      "Similarity Score: 0.6\n",
      "Title 1: Kill Bill: Vol. 1\n",
      "Title 2: Kill Bill: Vol. 2\n",
      "\n",
      "Similarity Score: 0.6666666666666666\n",
      "Title 1: Toy Story\n",
      "Title 2: Toy Story 2\n",
      "\n",
      "Similarity Score: 1.0\n",
      "Title 1: Alice in Wonderland\n",
      "Title 2: Alice in Wonderland\n",
      "\n",
      "Similarity Score: 0.6666666666666666\n",
      "Title 1: American Pie\n",
      "Title 2: American Pie 2\n",
      "\n",
      "Similarity Score: 0.6666666666666666\n",
      "Title 1: Jurassic Park\n",
      "Title 2: Jurassic Park III\n",
      "\n",
      "Similarity Score: 0.6666666666666666\n",
      "Title 1: Paranormal Activity 2\n",
      "Title 2: Paranormal Activity\n",
      "\n",
      "Similarity Score: 1.0\n",
      "Title 1: Planet of the Apes\n",
      "Title 2: Planet of the Apes\n",
      "\n",
      "Similarity Score: 0.6666666666666666\n",
      "Title 1: Scary Movie\n",
      "Title 2: Scary Movie 2\n",
      "\n",
      "Similarity Score: 0.6666666666666666\n",
      "Title 1: Scary Movie\n",
      "Title 2: Scary Movie 3\n",
      "\n",
      "Similarity Score: 0.6666666666666666\n",
      "Title 1: Mad Max\n",
      "Title 2: Mad Max 2\n",
      "\n",
      "Similarity Score: 0.6666666666666666\n",
      "Title 1: Final Destination 2\n",
      "Title 2: Final Destination\n",
      "\n",
      "Similarity Score: 0.6666666666666666\n",
      "Title 1: Bad Boys\n",
      "Title 2: Bad Boys II\n",
      "\n",
      "Similarity Score: 0.75\n",
      "Title 1: Men in Black\n",
      "Title 2: Men in Black II\n",
      "\n",
      "Similarity Score: 0.6666666666666666\n",
      "Title 1: Mission: Impossible III\n",
      "Title 2: Mission: Impossible\n",
      "\n",
      "Similarity Score: 0.6666666666666666\n",
      "Title 1: The Final Destination\n",
      "Title 2: Final Destination\n",
      "\n",
      "Similarity Score: 0.8\n",
      "Title 1: The Hills Have Eyes\n",
      "Title 2: The Hills Have Eyes II\n",
      "\n",
      "Similarity Score: 0.6666666666666666\n",
      "Title 1: Mission: Impossible\n",
      "Title 2: Mission: Impossible II\n",
      "\n",
      "Similarity Score: 0.6666666666666666\n",
      "Title 1: Final Destination 3\n",
      "Title 2: Final Destination\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Finds similar titles/descriptions\n",
    "def similar(texts, jaccard_threshold=0.6):\n",
    "    # Create a dictionary to store the similar texts\n",
    "    similar_texts = {}\n",
    "    \n",
    "    # Loop through each name in the list\n",
    "    for i in tqdm(range(len(texts))):\n",
    "        for j in range(i+1, len(texts)):\n",
    "            similarity_score = jaccard(texts[i], texts[j])\n",
    "            if similarity_score >= jaccard_threshold:\n",
    "                similar_texts[(texts[i], texts[j])] = similarity_score\n",
    "    return similar_texts\n",
    "\n",
    "# Example usage:    \n",
    "titles = Movies['Title'][0:500]\n",
    "similar_titles = similar(titles)\n",
    "# Print titles in a way that is easier to read\n",
    "\n",
    "for (desc1, desc2), score in similar_titles.items():\n",
    "    print(f\"Similarity Score: {score}\")\n",
    "    print(f\"Title 1: {desc1}\")\n",
    "    print(f\"Title 2: {desc2}\")\n",
    "    print()\n",
    "# 0.5 secs on 786"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{('J a s o n', 'N o j a n'): 0.8}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar(['J a s o n', 'N o j a n', 'N i k l a s', 'A m a l i e'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 95/7855 [01:05<1:29:34,  1.44it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Example usage for finding similar descriptions\u001b[39;00m\n\u001b[0;32m      2\u001b[0m reviews \u001b[38;5;241m=\u001b[39m Reviews[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReview\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m similar_descriptions \u001b[38;5;241m=\u001b[39m \u001b[43msimilar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreviews\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjaccard_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Print descriptions in a way that is easier to read\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (desc1, desc2), score \u001b[38;5;129;01min\u001b[39;00m similar_descriptions\u001b[38;5;241m.\u001b[39mitems():\n",
      "Cell \u001b[1;32mIn[17], line 9\u001b[0m, in \u001b[0;36msimilar\u001b[1;34m(names, jaccard_threshold)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(names))):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(names)):\n\u001b[1;32m----> 9\u001b[0m         similarity_score \u001b[38;5;241m=\u001b[39m \u001b[43mjaccard\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m similarity_score \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m jaccard_threshold:\n\u001b[0;32m     11\u001b[0m             similar_names[(names[i], names[j])] \u001b[38;5;241m=\u001b[39m similarity_score\n",
      "Cell \u001b[1;32mIn[9], line 4\u001b[0m, in \u001b[0;36mjaccard\u001b[1;34m(title1, title2)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjaccard\u001b[39m(title1, title2):\n\u001b[0;32m      3\u001b[0m     words1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mstr\u001b[39m(title1)\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39msplit())\n\u001b[1;32m----> 4\u001b[0m     words2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtitle2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Compute the intersection and union of the sets\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     intersection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(words1\u001b[38;5;241m.\u001b[39mintersection(words2))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Example usage for finding similar descriptions\n",
    "reviews = Reviews['Review']\n",
    "similar_descriptions = similar(reviews, jaccard_threshold=0.4)\n",
    "\n",
    "for (desc1, desc2), score in similar_descriptions.items():\n",
    "    print(f\"Similarity Score: {score}\")\n",
    "    print(f\"Description 1: {desc1}\")\n",
    "    print(f\"Description 2: {desc2}\") \n",
    "    print()\n",
    "\n",
    "# tqdm estimates ~1:20 hours for 786 reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\PC/nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.12_3.12.2032.0_x64__qbz5n2kfra8p0\\\\nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.12_3.12.2032.0_x64__qbz5n2kfra8p0\\\\share\\\\nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.12_3.12.2032.0_x64__qbz5n2kfra8p0\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\PC\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 44\u001b[0m\n\u001b[0;32m     42\u001b[0m movie_id \u001b[38;5;241m=\u001b[39m movies[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     43\u001b[0m raw \u001b[38;5;241m=\u001b[39m get_movie_reviews(movie_id)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 44\u001b[0m clean \u001b[38;5;241m=\u001b[39m \u001b[43mget_movie_reviews_cleaned\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmovie_id\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     45\u001b[0m lemmatized \u001b[38;5;241m=\u001b[39m get_movie_reviews_lemmatized(movie_id)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaw review: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mraw\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 33\u001b[0m, in \u001b[0;36mget_movie_reviews_cleaned\u001b[1;34m(movie_id)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_movie_reviews_cleaned\u001b[39m(movie_id):\n\u001b[0;32m     32\u001b[0m     movie_reviews \u001b[38;5;241m=\u001b[39m get_movie_reviews(movie_id)\n\u001b[1;32m---> 33\u001b[0m     movie_reviews_cleaned \u001b[38;5;241m=\u001b[39m \u001b[43mmovie_reviews\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclean_text_string\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m movie_reviews_cleaned\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\series.py:4357\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4248\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4249\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4252\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4253\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FrameOrSeriesUnion:\n\u001b[0;32m   4254\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4255\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4256\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4355\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4356\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\apply.py:1043\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1040\u001b[0m     \u001b[38;5;66;03m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m-> 1043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\apply.py:1098\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1092\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   1093\u001b[0m         \u001b[38;5;66;03m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m         \u001b[38;5;66;03m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[0;32m   1095\u001b[0m         \u001b[38;5;66;03m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[0;32m   1096\u001b[0m         \u001b[38;5;66;03m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m         \u001b[38;5;66;03m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[1;32m-> 1098\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1100\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1101\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1102\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1105\u001b[0m     \u001b[38;5;66;03m# GH 25959 use pd.array instead of tolist\u001b[39;00m\n\u001b[0;32m   1106\u001b[0m     \u001b[38;5;66;03m# so extension arrays can be used\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(pd_array(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\_libs\\lib.pyx:2859\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m, in \u001b[0;36mclean_text_string\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclean_text_string\u001b[39m(text):\n\u001b[1;32m----> 2\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m \u001b[43mword_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     clean_tokens \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m tokens:\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;66;03m# Convert to lowercase\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\nltk\\tokenize\\__init__.py:142\u001b[0m, in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mword_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m, preserve_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    128\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;124;03m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;124;03m    :type preserve_line: bool\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 142\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msent_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    144\u001b[0m         token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer\u001b[38;5;241m.\u001b[39mtokenize(sent)\n\u001b[0;32m    145\u001b[0m     ]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\nltk\\tokenize\\__init__.py:119\u001b[0m, in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msent_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    110\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;124;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43m_get_punkt_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(text)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\nltk\\tokenize\\__init__.py:105\u001b[0m, in \u001b[0;36m_get_punkt_tokenizer\u001b[1;34m(language)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_punkt_tokenizer\u001b[39m(language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     98\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;124;03m    A constructor for the PunktTokenizer that utilizes\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03m    a lru cache for performance.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;124;03m    :type language: str\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPunktTokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\nltk\\tokenize\\punkt.py:1744\u001b[0m, in \u001b[0;36mPunktTokenizer.__init__\u001b[1;34m(self, lang)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   1743\u001b[0m     PunktSentenceTokenizer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m-> 1744\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_lang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\nltk\\tokenize\\punkt.py:1749\u001b[0m, in \u001b[0;36mPunktTokenizer.load_lang\u001b[1;34m(self, lang)\u001b[0m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_lang\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   1747\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find\n\u001b[1;32m-> 1749\u001b[0m     lang_dir \u001b[38;5;241m=\u001b[39m \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtokenizers/punkt_tab/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlang\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_params \u001b[38;5;241m=\u001b[39m load_punkt_params(lang_dir)\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lang \u001b[38;5;241m=\u001b[39m lang\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\nltk\\data.py:579\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    577\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[0;32m    578\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 579\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\PC/nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.12_3.12.2032.0_x64__qbz5n2kfra8p0\\\\nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.12_3.12.2032.0_x64__qbz5n2kfra8p0\\\\share\\\\nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.12_3.12.2032.0_x64__qbz5n2kfra8p0\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\PC\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "def clean_text_string(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    clean_tokens = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        # Convert to lowercase\n",
    "        token = token.lower()\n",
    "        \n",
    "        # Remove punctuation\n",
    "        if token not in string.punctuation:\n",
    "            # Remove stopwords\n",
    "            if token not in stopwords.words('english'):\n",
    "                clean_tokens.append(token)\n",
    "\n",
    "    return ' '.join(clean_tokens)\n",
    "\n",
    "def lemmatize_text_string(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatized_tokens = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        lemmatized_tokens.append(lemmatizer.lemmatize(token))\n",
    "    \n",
    "    return ' '.join(lemmatized_tokens)\n",
    "\n",
    "def get_movie_reviews(movie_id):\n",
    "    movie_reviews = reviews[reviews['Movie ID'] == movie_id]['Review']\n",
    "    return movie_reviews\n",
    "\n",
    "def get_movie_reviews_cleaned(movie_id):\n",
    "    movie_reviews = get_movie_reviews(movie_id)\n",
    "    movie_reviews_cleaned = movie_reviews.apply(clean_text_string)\n",
    "    return movie_reviews_cleaned\n",
    "\n",
    "def get_movie_reviews_lemmatized(movie_id):\n",
    "    movie_reviews = get_movie_reviews(movie_id)\n",
    "    movie_reviews_lemmatized = movie_reviews.apply(lemmatize_text_string)\n",
    "    return movie_reviews_lemmatized\n",
    "\n",
    "# Test on first movie, first review\n",
    "movie_id = movies['ID'][0]\n",
    "raw = get_movie_reviews(movie_id)[0]\n",
    "clean = get_movie_reviews_cleaned(movie_id)[0]\n",
    "lemmatized = get_movie_reviews_lemmatized(movie_id)[0]\n",
    "print(f\"Raw review: {raw}\")\n",
    "print(f\"Cleaned review: {clean}\")\n",
    "print(f\"Lemmatized review: {lemmatized}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Shawshank Redemption is written and directed by Frank Darabont. It is an adaptation of the Stephen King novella Rita Hayworth and Shawshank Redemption. Starring Tim Robbins and Morgan Freeman, the film portrays the story of Andy Dufresne (Robbins), a banker who is sentenced to two life sentences at Shawshank State Prison for apparently murdering his wife and her lover. Andy finds it tough going but finds solace in the friendship he forms with fellow inmate Ellis \"Red\" Redding (Freeman). While things start to pick up when the warden finds Andy a prison job more befitting his talents as a banker. However, the arrival of another inmate is going to vastly change things for all of them.There was no fanfare or bunting put out for the release of the film back in 94, with a title that didn\\'t give much inkling to anyone about what it was about, and with Columbia Pictures unsure how to market it, Shawshank Redemption barely registered at the box office. However, come Academy Award time the film received several nominations, and although it won none, it stirred up interest in the film for its home entertainment release. The rest, as they say, is history. For the film finally found an audience that saw the film propelled to almost mythical proportions as an endearing modern day classic. Something that has delighted its fans, whilst simultaneously baffling its detractors. One thing is for sure, though, is that which ever side of the Shawshank fence you sit on, the film continues to gather new fans and simply will never go away or loose that mythical status.It\\'s possibly the simplicity of it all that sends some haters of the film into cinematic spasms. The implausible plot and an apparent sentimental edge that makes a nonsense of prison life, are but two chief complaints from those that dislike the film with a passion. Yet when characters are this richly drawn, and so movingly performed, it strikes me as churlish to do down a human drama that\\'s dealing in hope, friendship and faith. The sentimental aspect is indeed there, but that acts as a counterpoint to the suffering, degradation and shattering of the soul involving our protagonist. Cosy prison life you say? No chance. The need for human connection is never more needed than during incarceration, surely? And given the quite terrific performances of Robbins (never better) & Freeman (sublimely making it easy), it\\'s the easiest thing in the world to warm to Andy and Red.Those in support aren\\'t faring too bad either. Bob Gunton is coiled spring smarm as Warden Norton, James Whitmore is heart achingly great as the \"Birdman Of Shawshank,\" Clancy Brown is menacing as antagonist Capt. Byron Hadley, William Sadler amusing as Heywood & Mark Rolston is impressively vile as Bogs Diamond. Then there\\'s Roger Deakins\\' lush cinematography as the camera gracefully glides in and out of the prison offering almost ethereal hope to our characters (yes, they are ours). The music pings in conjunction with the emotional flow of the movie too. Thomas Newman\\'s score is mostly piano based, dovetailing neatly with Andy\\'s state of mind, while the excellently selected soundtrack ranges from the likes of Hank Williams to the gorgeous Le Nozze di Figaro by Mozart.If you love Shawshank then it\\'s a love that lasts a lifetime. Every viewing brings the same array of emotions - anger - revilement - happiness - sadness - inspiration and a warmth that can reduce the most hardened into misty eyed wonderment. Above all else, though, Shawshank offers hope - not just for characters in a movie - but for a better life and a better world for all of us. 10/10.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
